<?php

namespace Emilia\EcoFriendlyRobotsTxt;

/**
 * Handles the eco-friendly robots.txt modifications.
 */
class Plugin {

	const BACKUP_PATH = ABSPATH . 'robots.txt.eco-friendly-backup';

	/**
	 * Initialize the hooks and filters.
	 */
	public function init() {
		add_filter( 'robots_txt', [ $this, 'modify_robots_txt' ], 10, 2 );
		register_activation_hook( __FILE__, [ $this, 'backup_static_robots_txt' ] );
		register_deactivation_hook( __FILE__, [ $this, 'restore_static_robots_txt' ] );
	}

	/**
	 * Backs up the static robots.txt file if it exists.
	 */
	public function backup_static_robots_txt() {
		$robots_path = ABSPATH . 'robots.txt';
		if ( file_exists( $robots_path ) ) {
			// phpcs:ignore Generic.Commenting.Todo.TaskFound
			// @todo Ask for user consent before proceeding.
			// This step will need to be handled via admin notice or a settings page.
			// For the sake of this example, we'll assume consent is given.

			$wp_filesystem = $this->get_filesystem();
			$wp_filesystem::move( $robots_path, self::BACKUP_PATH );
		}
	}

	/**
	 * Restores the static robots.txt file upon plugin deactivation.
	 *
	 * @uses WP_Filesystem
	 */
	public function restore_static_robots_txt() {
		if ( file_exists( self::BACKUP_PATH ) ) {
			$robots_path = ABSPATH . 'robots.txt';

			$wp_filesystem = $this->get_filesystem();
			$wp_filesystem::move( self::BACKUP_PATH, $robots_path );
		}
	}

	/**
	 * Modifies the content of the dynamic robots.txt generated by WordPress.
	 *
	 * @param string $output      The original robots.txt content.
	 * @param bool   $site_public Whether the site is public.
	 *
	 * @return string Modified robots.txt content.
	 */
	public function modify_robots_txt( $output, $site_public ) {
		if ( ! $site_public ) {
			return "User-agent: *\nDisallow: /\n";
		}

		$whitelist = [
			'Googlebot', // Google.
			'Bingbot',   // Bing.
			'Slurp',     // Yahoo.
			'DuckDuckBot', // DuckDuckGo.
			'ia_archiver', // Archive.org.
		];

		$robots_txt = "User-agent: *\nDisallow: /\n";
		foreach ( $whitelist as $crawler ) {
			$robots_txt .= "User-agent: $crawler\nAllow: /\n";
		}

		// Keep existing Sitemap references.
		if ( strpos( $output, 'Sitemap: ' ) !== false ) {
			preg_match_all( '/Sitemap: (.+)/', $output, $matches );
			foreach ( $matches[0] as $sitemap ) {
				$robots_txt .= "$sitemap\n";
			}
		}

		return $robots_txt;
	}

	/**
	 * Retrieves the WordPress filesystem.
	 *
	 * @return WP_Filesystem
	 */
	private function get_filesystem() {
		global $wp_filesystem;

		require_once ABSPATH . '/wp-admin/includes/file.php';
		WP_Filesystem();
		return $wp_filesystem;
	}
}
